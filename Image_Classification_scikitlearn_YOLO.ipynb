{"cells":[{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3589,"status":"ok","timestamp":1706632166227,"user":{"displayName":"CS21B1027- Manvitha Nandyala","userId":"15476616746162460083"},"user_tz":-330},"id":"DiLzA47olBp6","outputId":"89712832-2f09-44ab-c326-997f0ed16b93"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":651,"status":"ok","timestamp":1706630518075,"user":{"displayName":"CS21B1027- Manvitha Nandyala","userId":"15476616746162460083"},"user_tz":-330},"id":"AaSlqJYVlO4V"},"outputs":[],"source":["\"\"\"import os\n","from skimage.io import imread\n","from skimage.transform import resize\n","import numpy as np\n","import pickle\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"557EBRaioDMY","outputId":"dac94ee1-fc5a-4c32-f35d-f562a9e633e0"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-3-e8223a74c8ee>:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  data = np.asarray(data)\n"]}],"source":["#1. prepare data\n","\n","#where the data is present\n","\"\"\"input_dir='/content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn/train'\n","categories=['santa','not-a-santa']\n","\n","data=[]\n","labels=[]\n","\n","#traversing through all the images\n","for category_idx, category in enumerate(categories):  #iterates through the 2 catagoris\n","    for file in os.listdir(os.path.join(input_dir, category)): #iterates through the imags in each catagori\n","        img_path = os.path.join(input_dir, category, file) #gets each image\n","        img = imread(img_path)\n","        img = resize(img, (15, 15)) #resize the image\n","        data.append(img.flatten()) #convert the image to a 1d array and append to data list\n","        labels.append(category_idx) #for the particular 1d image append the catagory to labels\n","\n","#convert both the list to a numpy array\n","data = np.asarray(data)\n","labels = np.asarray(labels)\"\"\""]},{"cell_type":"code","execution_count":23,"metadata":{"id":"TzMuggtNp9FT","executionInfo":{"status":"ok","timestamp":1706631049405,"user_tz":-330,"elapsed":361,"user":{"displayName":"CS21B1027- Manvitha Nandyala","userId":"15476616746162460083"}}},"outputs":[],"source":["#2. train_test_split\n","\"\"\"from sklearn.model_selection import train_test_split\n","\n","x_train,x_test,y_train,y_test=train_test_split(data,labels, test_size=0.2, shuffle=True, stratify=labels )\n","#stratify --> to split the data properly into 2 catagories\"\"\"\n"]},{"cell_type":"code","source":["#3. train classifier\n","\"\"\"from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","\n","classifier = SVC()\n","\n","#parameters = [{'gamma': [0.01, 0.001, 0.0001], 'C': [1, 10, 100, 1000]}]\n","\n","#grid_search = GridSearchCV(classifier, parameters, cv=5, error_score='raise')  # Add error_score='raise'\n","\n","# Train the classifier with different parameter combinations\n","classifier.fit(x_train, y_train)\n","\n","# Print the best parameters found by the grid search\n","#print(\"Best Parameters:\", grid_search.best_params_)\"\"\""],"metadata":{"id":"dU5Zvcbj0wJD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls '/content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn/data1'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mA89lTpX37Qa","executionInfo":{"status":"ok","timestamp":1706632769086,"user_tz":-330,"elapsed":413,"user":{"displayName":"CS21B1027- Manvitha Nandyala","userId":"15476616746162460083"}},"outputId":"d38eb9e0-b678-4188-8410-d817fb2cbf84"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["santa_data\n"]}]},{"cell_type":"code","source":["DATA_DIR='/content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn/data1/santa_data'"],"metadata":{"id":"MgoesW9pNOp_","executionInfo":{"status":"ok","timestamp":1706632765296,"user_tz":-330,"elapsed":658,"user":{"displayName":"CS21B1027- Manvitha Nandyala","userId":"15476616746162460083"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PtJIz5xXNirq","executionInfo":{"status":"ok","timestamp":1706632323959,"user_tz":-330,"elapsed":11428,"user":{"displayName":"CS21B1027- Manvitha Nandyala","userId":"15476616746162460083"}},"outputId":"137f9c58-bd7e-4700-a2d6-50c744d47ca5"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.1.8-py3-none-any.whl (709 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m709.4/709.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Collecting thop>=0.1.1 (from ultralytics)\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.47.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: thop, ultralytics\n","Successfully installed thop-0.1.1.post2209072238 ultralytics-8.1.8\n"]}]},{"cell_type":"code","source":["import os\n","from ultralytics import YOLO"],"metadata":{"id":"iBgGzq1ZNnSP","executionInfo":{"status":"ok","timestamp":1706632651115,"user_tz":-330,"elapsed":4,"user":{"displayName":"CS21B1027- Manvitha Nandyala","userId":"15476616746162460083"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["#load the model\n","model=YOLO('yolov8n-cls.pt') #building the model from scratch\n","\n","#using the model\n","results=model.train(data=DATA_DIR, epochs=10, imgsz=64)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rTQ6Ne65O3j-","executionInfo":{"status":"ok","timestamp":1706633182750,"user_tz":-330,"elapsed":160478,"user":{"displayName":"CS21B1027- Manvitha Nandyala","userId":"15476616746162460083"}},"outputId":"571fed0b-d2b5-4ee0-f19b-2e54cb450502"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.8 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn/data1/santa_data, epochs=10, time=None, patience=50, batch=16, imgsz=64, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train2\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn/data1/santa_data/train... found 337 images in 2 classes âœ… \n","\u001b[34m\u001b[1mval:\u001b[0m /content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn/data1/santa_data/val... found 52 images in 2 classes âœ… \n","\u001b[34m\u001b[1mtest:\u001b[0m None...\n","Overriding model.yaml nc=1000 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    332802  ultralytics.nn.modules.head.Classify         [256, 2]                      \n","YOLOv8n-cls summary: 99 layers, 1440850 parameters, 1440850 gradients, 3.4 GFLOPs\n","Transferred 156/158 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train2', view at http://localhost:6006/\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn/data1/santa_data/train... 337 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 337/337 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn/data1/santa_data/val... 52 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n","Image sizes 64 train, 64 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns/classify/train2\u001b[0m\n","Starting training for 10 epochs...\n","\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/10         0G     0.6632          1         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:14<00:00,  1.48it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.769          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/10         0G      0.491          1         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:13<00:00,  1.60it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.10it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.923          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/10         0G     0.4197          1         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:13<00:00,  1.64it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.10it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.962          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/10         0G     0.3356          1         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:13<00:00,  1.62it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.00it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all      0.962          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/10         0G     0.2825          1         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:13<00:00,  1.69it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.24it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/10         0G     0.2323          1         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:13<00:00,  1.60it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.04it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/10         0G     0.2545          1         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:13<00:00,  1.60it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.13it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/10         0G     0.2145          1         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:16<00:00,  1.37it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.78it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/10         0G     0.2001          1         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:12<00:00,  1.78it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.79it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem       loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/10         0G     0.2078          1         64: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:12<00:00,  1.71it/s]\n","               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.95it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","10 epochs completed in 0.042 hours.\n","Optimizer stripped from runs/classify/train2/weights/last.pt, 3.0MB\n","Optimizer stripped from runs/classify/train2/weights/best.pt, 3.0MB\n","\n","Validating runs/classify/train2/weights/best.pt...\n","Ultralytics YOLOv8.1.8 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.20GHz)\n","YOLOv8n-cls summary (fused): 73 layers, 1437442 parameters, 0 gradients, 3.3 GFLOPs\n","\u001b[34m\u001b[1mtrain:\u001b[0m /content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn/data1/santa_data/train... found 337 images in 2 classes âœ… \n","\u001b[34m\u001b[1mval:\u001b[0m /content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn/data1/santa_data/val... found 52 images in 2 classes âœ… \n","\u001b[34m\u001b[1mtest:\u001b[0m None...\n"]},{"output_type":"stream","name":"stderr","text":["               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all          1          1\n","Speed: 0.0ms preprocess, 1.4ms inference, 0.0ms loss, 0.0ms postprocess per image\n","Results saved to \u001b[1mruns/classify/train2\u001b[0m\n","Results saved to \u001b[1mruns/classify/train2\u001b[0m\n"]}]},{"cell_type":"code","source":["#to save results in drive\n","!scp -r /content/runs '/content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn'"],"metadata":{"id":"NKHhi4YaPiKA","executionInfo":{"status":"ok","timestamp":1706633416861,"user_tz":-330,"elapsed":1173,"user":{"displayName":"CS21B1027- Manvitha Nandyala","userId":"15476616746162460083"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["#predict which catogery this image belongs to\n","#import torch\n","model=YOLO('/content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn (1)/results/classify/train2/weights/last.pt')\n","\n","#results=model('/content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn (1)/square.jpg')\n","results=model('/content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn (1)/download.jpg')\n","\n","#print(results)\n","\n","#to know what the iamge is\n","name_dict=results[0].names\n","probs=results[0].probs\n","\n","print(probs)\n","print(name_dict)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O4aIywG9R0ly","executionInfo":{"status":"ok","timestamp":1706635198438,"user_tz":-330,"elapsed":1899,"user":{"displayName":"CS21B1027- Manvitha Nandyala","userId":"15476616746162460083"}},"outputId":"8764d7cc-56ed-44c9-8ca4-727d15e0cd91"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","image 1/1 /content/gdrive/MyDrive/computer_vision_eng/image_classification_scikit_learn (1)/download.jpg: 64x64 not_santa 0.89, santa 0.11, 14.5ms\n","Speed: 3.9ms preprocess, 14.5ms inference, 0.1ms postprocess per image at shape (1, 3, 64, 64)\n","ultralytics.engine.results.Probs object with attributes:\n","\n","data: tensor([0.8852, 0.1148])\n","orig_shape: None\n","shape: torch.Size([2])\n","top1: 0\n","top1conf: tensor(0.8852)\n","top5: [0, 1]\n","top5conf: tensor([0.8852, 0.1148])\n","{0: 'not_santa', 1: 'santa'}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"unI2fenPVGRU"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNAojNStie3Upm1ZesZHs5Y"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}